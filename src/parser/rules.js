// This file was generated by lezer-generator. You probably shouldn't edit it.
const {LRParser} = require("@lezer/lr")
exports.parser = LRParser.deserialize({
  version: 13,
  states: "#YQYQPOOOOQO'#C^'#C^ObQPO'#ChOOQO'#Cb'#CbQYQPOOOjQPO,59SOxQPO,59SOOQO-E6`-E6`OOQO'#Cc'#CcO!WQPO'#CaOOQO'#Cj'#CjO!iQPO1G.nO!qQPO1G.nOOQO-E6a-E6aO!yQPO,59UOOQO7+$Y7+$YOOQO1G.p1G.p",
  stateData: "#[~OYOSZOS~ORPOSPO~O]TOaUO~ORWOSWO_TP`TP~ORWOSWO_TPbTP~ORWOSWO_TX`TXbTX~O_^O`_O~O_^Ob_O~ORWOSWO_TP`TPbTP~O",
  goto: "!T_PP`PPdkqPPPPyP}TQOSSYTUR`^QSORVSUXTU^R]XTROSQZTR[U",
  nodeNames: "âš  rules Head Symbol QuotedSymbol Production",
  maxTerm: 18,
  skippedNodes: [0],
  repeatNodeCount: 2,
  tokenData: "%y~RfX^!gpq!grs#[st#|tu$Xwx$m}!O%Y!O!P%e![!]%j!]!^%o!c!}$X#R#S$X#T#o$X#p#q%t#y#z!g$f$g!g#BY#BZ!g$IS$I_!g$I|$JO!g$JT$JU!g$KV$KW!g&FU&FV!g~!lYY~X^!gpq!g#y#z!g$f$g!g#BY#BZ!g$IS$I_!g$I|$JO!g$JT$JU!g$KV$KW!g&FU&FV!g~#_UOY#[Zr#[rs#qs#O#[#O#P#v#P~#[~#vOS~~#yPO~#[~$RQZ~OY#|Z~#|~$^TR~tu$X!Q![$X!c!}$X#R#S$X#T#o$X~$pUOY$mZw$mwx#qx#O$m#O#P%S#P~$m~%VPO~$m~%]P!`!a%`~%eO]~~%jO`~~%oOa~~%tOb~~%yO_~",
  tokenizers: [0],
  topRules: {"rules":[0,1]},
  tokenPrec: 0
})
